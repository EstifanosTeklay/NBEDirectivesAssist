{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5207c87-d25d-46d4-9022-7150ea563a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from groq import Groq\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm import tqdm  # tqdm used for progress visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d707687c-e730-4cfe-8a6b-aecc6aee88c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EstifanosT\n"
     ]
    }
   ],
   "source": [
    "h=os.getcwd()\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efb4b6b5-0f87-47d4-8f87-cc0d961bda84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing all JSON files\n",
    "json_folder_path = 'D:\\\\NBEDirectivesAssist\\\\ConvertedToJson\\\\'\n",
    "\n",
    "# List to hold all documents from all JSON files\n",
    "all_documents = []\n",
    "\n",
    "# Loop through each JSON file in the directory\n",
    "for json_file in os.listdir(json_folder_path):\n",
    "    if json_file.endswith(\".json\"):\n",
    "        json_file_path = os.path.join(json_folder_path, json_file)\n",
    "        with open(json_file_path, 'rt', encoding='utf-8') as f_in:\n",
    "            docs_raw = json.load(f_in)\n",
    "        \n",
    "        # Extract documents from the current JSON file\n",
    "        documents = []\n",
    "        for directive_id_dict in docs_raw:\n",
    "            for doc in directive_id_dict['sections']:\n",
    "                # Add additional fields to the doc\n",
    "                doc['document_id'] = directive_id_dict['document_id']\n",
    "                doc['title'] = directive_id_dict['title']\n",
    "                documents.append(doc)\n",
    "\n",
    "        # Append documents from this file to the global list\n",
    "        all_documents.extend(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "004e7ecf-ceb1-4bfe-bbae-d6ac98b4505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a new library compared to the previous modules. \n",
    "# Please perform \"pip install sentence_transformers==2.7.0\"\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# if you get an error do the following:\n",
    "# 1. Uninstall numpy \n",
    "# 2. Uninstall torch\n",
    "# 3. pip install numpy==1.26.4\n",
    "# 4. pip install torch\n",
    "# run the above cell, it should work\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef89ffc-48fb-48ed-830c-79d140c97110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#created the dense vector using the pre-trained model\n",
    "operations = []\n",
    "for doc in all_documents:\n",
    "    # Transforming the title into an embedding using the model\n",
    "    doc[\"content_vector\"] = model.encode(doc[\"content\"]).tolist()\n",
    "    operations.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1cb877-15f5-4d9f-b19b-6ad03a58cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Elasticsearch client\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "\n",
    "# Define index settings and mappings\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"text\"},\n",
    "            \"section_title\": {\"type\": \"text\"},\n",
    "            \"content\": {\"type\": \"text\"},\n",
    "            \"document_id\": {\"type\": \"keyword\"},\n",
    "            \"section_id\": {\"type\": \"integer\"}, # This section is the only integer field\n",
    "            \"content_vector\": {\"type\": \"dense_vector\", \"dims\": 768, \"index\": True, \"similarity\": \"cosine\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create index\n",
    "index_name = \"directivesanalysissvector\"\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e62c0d-8079-4f91-82d4-85aceb24745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index documents (`all_documents` is a list of dictionaries)\n",
    "\n",
    "for doc in tqdm(all_documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f150a0c-d5db-42ca-80f0-8a7edfd1020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search query\n",
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"content^10\", \"title\", \"section_title\", \"document_id\"],  # Only text fields\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Perform search\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    result_docs=[]\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468c710e-3f14-4ae6-88b7-6c8a495d8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search query\n",
    "def elastic_search(search_term):\n",
    "    vector_search_term = model.encode(search_term)\n",
    "    query = {\n",
    "    \"field\": \"content_vector\",\n",
    "    \"query_vector\": vector_search_term,\n",
    "    \"k\": 5,\n",
    "    \"num_candidates\": 10000, \n",
    "}\n",
    "   \n",
    "# Perform search\n",
    "    response = es_client.search(index=index_name, knn=query, source=[\"content\", \"section_id\", \"section_title\", \"document_id\",\"title\"])\n",
    "    result_docs=[]\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5ae697-df40-4c41-8459-77cdb4ceff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(search_term,search_results):\n",
    "    # Create the prompt for the LLM\n",
    "    prompt_template = \"\"\"\n",
    "You're National Bank of Ethiopia Directives assistant. Answer the QUESTION based on the CONTEXT from the directive document.\n",
    "Use  facts from the CONTEXT when answering the QUESTION.\n",
    "If the CONTEXT does not contain the answer, Answer from your general knowledge.\n",
    "\n",
    "QUESTION: {question}\n",
    "CONTEXT: {context}\n",
    "     \"\"\".strip()\n",
    "\n",
    "# Generate the context from the search results\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context += f\"section_id: {doc['section_id']}\\nsection_title: {doc['section_title']}\\npage_number: {doc['page_number']}\\ncontent: {doc['content']}\\ndocument_id: {doc['document_id']}\\ntitle: {doc['title']}\\n\\n\"\n",
    "\n",
    "# Format the prompt\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23f1ae5-8808-4d4b-b5d1-2b0761d8db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(search_term, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're National Bank of Ethiopia Directives assistant. Answer the QUESTION based on the CONTEXT from the directive document.\n",
    "Use  facts from the CONTEXT when answering the QUESTION.\n",
    "If the CONTEXT does not contain the answer, Answer from your general knowledge.\n",
    "    Question: {question}\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        # Use .get() to safely access dictionary keys\n",
    "        context += (\n",
    "            f\"section_id: {doc.get('section_id', 'N/A')}\\n\"\n",
    "            f\"section_title: {doc.get('section_title', 'N/A')}\\n\"\n",
    "            f\"page_number: {doc.get('page_number', 'N/A')}\\n\"\n",
    "            f\"content: {doc.get('content', 'N/A')}\\n\"\n",
    "            f\"document_id: {doc.get('document_id', 'N/A')}\\n\"\n",
    "            f\"title: {doc.get('title', 'N/A')}\\n\\n\"\n",
    "        )\n",
    "\n",
    "    # Format the prompt\n",
    "    prompt = prompt_template.format(question=search_term, context=context).strip()\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a0a6b5-181c-43f0-bc09-65eba448340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    # Initialize Groq client\n",
    "    client = Groq(api_key=\"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\")\n",
    "\n",
    "# Get the answer from the LLM model\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    "    )\n",
    "    llm_answer=chat_completion.choices[0].message.content\n",
    "# return the reslut\n",
    "    return llm_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1be7606-a6c6-4a49-ad8b-423bf70ccc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results=elastic_search(search_term)\n",
    "    prompt=build_prompt(query,search_results)\n",
    "    answer=llm(prompt)\n",
    "    return(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97074a5-dba5-4e51-9488-afa08bdb4905",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag('Tell me about board of directors size and composition?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a3a43-3757-4123-81a5-5d4f08779952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8943b53c-82e5-4b58-a7ef-61d6f6c80e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
